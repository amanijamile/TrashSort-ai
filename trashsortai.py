# -*- coding: utf-8 -*-
"""TrashSortAi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15-IDssyYJX_WclubM5ZQuYqm3HhPVnbm
"""

# Installing Required Packages
!pip install tensorflow            # Core DL framework (Keras included)
!pip install opencv-python         # For image preprocessing
!pip install scikit-learn          # For metrics (classification report, confusion matrix)
!pip install sentence-transformers # For NLP/FAQ functionality
!pip install ipywidgets            # For UI widgets

#Disabling GPU & displaying imports / basic Setup
import os
# Force TensorFlow to ignore GPUs
import random
import shutil
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import itertools
import cv2

# Verify no GPUs are visible
print("GPUs visible to TensorFlow:", tf.config.list_physical_devices('GPU'))

# Fix random seeds for reproducibility
random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)

# Paths and class names
#  - We will clone https://github.com/garythung/trashnet.git into /content/trashnet
#  - Then unzip /content/trashnet/data/dataset-resized.zip
BASE_REPO_DIR = '/content/trashnet'
ZIP_PATH      = os.path.join(BASE_REPO_DIR, 'data', 'dataset-resized.zip')
BASE_DIR      = '/content/trashnet/data/dataset-resized'

CLASS_NAMES = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']
NUM_CLASSES = len(CLASS_NAMES)

# Input image size for the CNN
IMG_HEIGHT = 128
IMG_WIDTH  = 128
BATCH_SIZE = 32  # Reasonable batch size for CPU

# Cloning the TrashNet GitHub repository
if not os.path.isdir(BASE_REPO_DIR):
    !git clone https://github.com/garythung/trashnet.git {BASE_REPO_DIR}
else:
    print("/content/trashnet already exists.")

# Unzipping the ‚Äúdataset-resized.zip‚Äù into /content/trashnet/data/
zip_path = '/content/trashnet/data/dataset-resized.zip'
assert os.path.isfile(zip_path), f"Expected to find {zip_path}"
!unzip -q /content/trashnet/data/dataset-resized.zip -d /content/trashnet/data/
print("Unzipped dataset-resized.zip into /content/trashnet/data/")

# Verifying that the six class folders exist
BASE_DIR = '/content/trashnet/data/dataset-resized'
CLASS_NAMES = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']
NUM_CLASSES = len(CLASS_NAMES)

for cls in CLASS_NAMES:
    cls_path = os.path.join(BASE_DIR, cls)
    assert os.path.isdir(cls_path), f"Missing folder: {cls_path}"
print("Found all six class folders under:", BASE_DIR)

# Creating an 80/20 Train/Validation Split under /content/data_split/
DATA_SPLIT_DIR = '/content/data_split/'

for cls in CLASS_NAMES:
    src_folder    = os.path.join(BASE_DIR, cls)
    train_cls_dir = os.path.join(DATA_SPLIT_DIR, 'train', cls)
    val_cls_dir   = os.path.join(DATA_SPLIT_DIR, 'val', cls)
    os.makedirs(train_cls_dir, exist_ok=True)
    os.makedirs(val_cls_dir,   exist_ok=True)

    all_images = os.listdir(src_folder)
    random.shuffle(all_images)
    split_idx = int(len(all_images) * 0.8)

    for idx, img_name in enumerate(all_images):
        src_path = os.path.join(src_folder, img_name)
        if idx < split_idx:
            dst_path = os.path.join(train_cls_dir, img_name)
        else:
            dst_path = os.path.join(val_cls_dir, img_name)
        shutil.copy(src_path, dst_path)

print("Train/Validation split created under:", DATA_SPLIT_DIR)

#Data Augmentation
train_dir = os.path.join(DATA_SPLIT_DIR, 'train')
val_dir   = os.path.join(DATA_SPLIT_DIR, 'val')

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.15,
    height_shift_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    classes=CLASS_NAMES,
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    classes=CLASS_NAMES,
    shuffle=False
)

# Computing Class Weights to Handle Imbalance
train_labels = train_generator.classes  # integer labels for all train samples
class_weights_vals = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_labels),
    y=train_labels
)
class_weights = {i: w for i, w in enumerate(class_weights_vals)}
print("Class weights:", class_weights)

# Building & Compiling a CNN Model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),

    layers.Dense(NUM_CLASSES, activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

#Training the CNN with Callbacks (EarlyStopping & ReduceLROnPlateau)
reduce_lr = callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=2,
    verbose=1,
    min_lr=1e-7
)
early_stop = callbacks.EarlyStopping(
    monitor='val_accuracy',
    patience=4,
    verbose=1,
    restore_best_weights=True
)

EPOCHS = 20
history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    class_weight=class_weights,
    callbacks=[reduce_lr, early_stop]
)

#Saving the Trained Model for Later Inference
model_save_path = '/content/basic_cnn_trash_classifier.h5'
model.save(model_save_path)
print("Model saved to:", model_save_path)

#Plotting Training & Validation Accuracy/Loss Curves
hist_acc     = history.history['accuracy']
hist_val_acc = history.history['val_accuracy']
hist_loss    = history.history['loss']
hist_val_loss= history.history['val_loss']
epochs_range = range(1, len(hist_acc) + 1)

plt.figure(figsize=(14, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(epochs_range, hist_acc,     label='Train Acc')
plt.plot(epochs_range, hist_val_acc, label='Val Acc')
plt.title('Training vs. Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(epochs_range, hist_loss,     label='Train Loss')
plt.plot(epochs_range, hist_val_loss, label='Val Loss')
plt.title('Training vs. Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Computing Classification Report & Confusion Matrix on Validation
# 1) Predict on validation set
val_steps = val_generator.samples // val_generator.batch_size + 1
pred_probs = model.predict(val_generator, steps=val_steps, verbose=1)
y_pred = np.argmax(pred_probs, axis=1)
y_true = val_generator.classes  # integer labels in fixed order

# 2) Classification report
report = classification_report(
    y_true,
    y_pred,
    target_names=CLASS_NAMES,
    digits=4
)
print("Classification Report \n")
print(report)

# 3) Confusion matrix
cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(6, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix (Validation)')
plt.colorbar()
tick_marks = np.arange(len(CLASS_NAMES))
plt.xticks(tick_marks, CLASS_NAMES, rotation=45)
plt.yticks(tick_marks, CLASS_NAMES)

thresh = cm.max() / 2.0
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(
        j, i, format(cm[i, j], 'd'),
        horizontalalignment="center",
        color="white" if cm[i, j] > thresh else "black"
    )

plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

#Defining an inference function (reload model if needed)
def predict_waste(img_bytes):
    """
    - img_bytes: raw bytes of an uploaded image
    - Returns: (predicted_label, bin_suggestion, confidence_score)
    """
    # Decode bytes ‚Üí BGR ‚Üí convert to RGB
    nparr = np.frombuffer(img_bytes, np.uint8)
    img   = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    img   = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img   = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))
    img   = img.astype('float32') / 255.0
    img   = np.expand_dims(img, axis=0)  # Shape: (1, H, W, 3)

    preds = model.predict(img)[0]  # (NUM_CLASSES,)
    best_idx = np.argmax(preds)
    label = CLASS_NAMES[best_idx]
    confidence = float(preds[best_idx])

    # Map label ‚Üí bin suggestion
    bin_map = {
        'plastic':   'Blue Recycling Bin',
        'paper':     'Blue Recycling Bin',
        'glass':     'Green Recycling Bin',
        'metal':     'Blue Recycling Bin',
        'cardboard': 'Blue Recycling Bin',
        'trash':     'Landfill (General Trash Bin)'
    }
    suggestion = bin_map.get(label, 'Unknown')

    return label, suggestion, confidence

#Preparing FAQ list & compute sentence embeddings (NLP)
from sentence_transformers import SentenceTransformer, util
import ipywidgets as widgets
from IPython.display import display, Image, clear_output
import cv2
faq_list = [
    {"question": "where do i dispose of a plastic bottle",
     "answer": "Plastic bottles go in the Blue Recycling Bin. Rinse them first."},
    {"question": "can i compost banana peels",
     "answer": "Yes, banana peels are organic and belong in your compost or Organic Waste bin."},
    {"question": "what do i do with glass jars",
     "answer": "Glass jars go in the Green Recycling Bin. Rinse and remove labels."},
    {"question": "how should i throw away pizza boxes",
     "answer": "If heavily soiled, put in the Landfill. If clean, flatten for the Blue Recycling Bin."},
    {"question": "are aluminum cans recyclable",
     "answer": "Yes, aluminum cans go in the Blue Recycling Bin. Crush them if possible."},
    {"question": "where does paper go",
     "answer": "Clean paper goes in the Blue Recycling Bin. Shredded paper should be bagged."},
    {"question": "what about styrofoam",
     "answer": "Most Styrofoam is NOT curbside‚Äêrecyclable. Check local drop‚Äêoff or put in the Landfill."},
    {"question": "do batteries go in recycling",
     "answer": "No. Household batteries go to a hazardous waste drop‚Äêoff‚Äîdo NOT put in regular bins."},
    {"question": "can i recycle plastic bags",
     "answer": "Plastic bags go to grocery‚Äêstore drop‚Äêoff bins, not curbside."},
    {"question": "how do i get rid of old electronics",
     "answer": "E-waste must go to certified e-waste recycling facilities."},
    {"question": "is cardboard recyclable",
     "answer": "Yes. Flatten cardboard boxes and place them in the Blue Recycling Bin."}
]

# Load sentence-transformers model for embeddings
embedder = SentenceTransformer('all-MiniLM-L6-v2')

# Compute embeddings for all FAQ questions
faq_questions  = [item['question'] for item in faq_list]
faq_embeddings = embedder.encode(faq_questions, convert_to_tensor=True)

#Defining function to retrieve the best FAQ answer
def get_faq_answer(user_query):
    """
    - user_query: String typed by the user
    - Returns: Best-matched answer or fallback message.
    """
    q = user_query.strip().lower()
    if not q:
        return "Please enter a valid question."

    q_emb = embedder.encode(q, convert_to_tensor=True)
    cos_scores = util.pytorch_cos_sim(q_emb, faq_embeddings)[0]
    best_idx   = int(np.argmax(cos_scores.cpu().numpy()))
    best_score = float(cos_scores[best_idx])

    # If top similarity ‚â• 0.65, return that FAQ answer
    if best_score >= 0.65:
        return faq_list[best_idx]['answer']
    else:
        return "Sorry, I‚Äôm not sure. Please check your local recycling guidelines."

#‚ÄúCard‚Äù Style Tabs for Classifier & Chatbot
from IPython.display import display, HTML, Image
import ipywidgets as widgets

# 1) CSS Injection for larger, bold tab labels
display(HTML("""
<style>
  .p-Widget.jupyter-widgets .p-TabBar-tab {
    font-size: 1.1em !important;
    font-weight: bold !important;
  }
</style>
"""))

# 2) --- Tab 1: Waste Classifier widgets & logic ---
file_upload = widgets.FileUpload(
    accept='image/*',
    multiple=False,
    description='Upload Image'
)
output1 = widgets.Output()

def on_upload_change(change):
    output1.clear_output()
    for _, file_info in file_upload.value.items():
        img_bytes = file_info['content']
        with output1:
            display(Image(data=img_bytes, format='png'))
            label, bin_suggestion, confidence = predict_waste(img_bytes)
            print(f"Predicted: {label}  (Confidence: {confidence:.2f})")
            print(f"Suggested Bin: {bin_suggestion}")

file_upload.observe(on_upload_change, names='value')

# Build Tab 1 ‚Äúcard‚Äù
header1 = widgets.HTML(
    "<div style='background:#4CAF50; color:white; padding:8px; "
    "border-top-left-radius:6px; border-top-right-radius:6px; font-size:1.2em;'>"
    "üñºÔ∏è Waste Classifier</div>"
)
body1 = widgets.VBox([file_upload, output1], layout=widgets.Layout(
    border='1px solid #4CAF50',
    border_top='none',
    padding='10px',
    border_bottom_left_radius='6px',
    border_bottom_right_radius='6px',
    margin='0 10px 10px 10px'
))
tab1 = widgets.VBox([header1, body1])

# 3) --- Tab 2: Recycling FAQ Chatbot widgets & logic ---
text_input = widgets.Text(
    placeholder='Type your recycling question here‚Ä¶',
    description='Question:',
    layout=widgets.Layout(width='80%')
)
submit_btn = widgets.Button(description='Ask')
output2 = widgets.Output()

def on_submit_click(b):
    output2.clear_output()
    answer = get_faq_answer(text_input.value)
    with output2:
        print(answer)

submit_btn.on_click(on_submit_click)

# Build Tab 2 ‚Äúcard‚Äù
header2 = widgets.HTML(
    "<div style='background:#2196F3; color:white; padding:8px; "
    "border-top-left-radius:6px; border-top-right-radius:6px; font-size:1.2em;'>"
    "üí¨ Recycling FAQ Chatbot</div>"
)
body2 = widgets.VBox([text_input, submit_btn, output2], layout=widgets.Layout(
    border='1px solid #2196F3',
    border_top='none',
    padding='10px',
    border_bottom_left_radius='6px',
    border_bottom_right_radius='6px',
    margin='0 10px 10px 10px'
))
tab2 = widgets.VBox([header2, body2])

# 4) Combine into a Tab widget
tab = widgets.Tab(children=[tab1, tab2], layout=widgets.Layout(width='auto'))
tab.set_title(0, 'Classifier')
tab.set_title(1, 'Chatbot')

display(tab)